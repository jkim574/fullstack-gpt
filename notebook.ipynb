{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ChatPromptTemplate is to create a template from messages.\n",
    "- prompttemplate is to create a template from string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature = 0.1) # -> gpt-3.5 turbo model\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Korea and Thailand is approximately 3,000 kilometers (1,864 miles).'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = PromptTemplate.from_template(\"what is the distance between {country_a} and {country_b}\")\n",
    "#llm = OpenAI() -> text-davinci model\n",
    "    # temperature determines how creative or random the model is.\n",
    "\n",
    "prompt = template.format(country_a = \"Korea\", country_b = \"Thailand\")\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict message using gpt-3.5 turbo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao! Il mio nome è Paolo. La distanza tra il Messico e la Thailandia è di circa 17.000 chilometri.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "message = [\n",
    "    SystemMessage(content=\"You are a geography expert. And you only reply in Italian.\"),\n",
    "    AIMessage(content=\"Ciao, mi ciamo Paulo.\"),\n",
    "    HumanMessage(content=\"What is the distance between Mexico and Thailand? Also, What is your name? \")\n",
    "]\n",
    "\n",
    "chat.predict_messages(message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we will use ChatPromptTemplate to make it simpler.\n",
    "- template -> format -> predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The distance between Korea and Thailand varies depending on the specific locations. The approximate distance between Seoul, South Korea, and Bangkok, Thailand, is around 4,500 kilometers (2,800 miles). However, please note that this is a straight-line distance and actual travel distances may differ.\\n\\nAs for my name, I am an AI language model developed by OpenAI, and I don\\'t have a personal name. You can simply refer to me as \"Assistant.\" How can I assist you further?')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "        (\"ai\", \"My name is {name}.\"),\n",
    "        (\"human\", \"What is the distance between {country_a} and {country_b}? Also, What is your name?\")\n",
    "    ]\n",
    ")\n",
    " \n",
    "prompt = template.format_messages(\n",
    "    language = \"English\",\n",
    "    name = \"Joong Ho\",\n",
    "    country_a = \"Korea\",\n",
    "    country_b = \"Thailand\"\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OutputParser and LangChain Expression Language(LCEL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need Output Parser to transform the response from LLM\n",
    "- It could be List, Dictionary, or database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseOutputParser \n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    \n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip,items))\n",
    "\n",
    "# p = CommaOutputParser()\n",
    "# p.parse(\"Hello, How, are,you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'orange',\n",
       " 'yellow',\n",
       " 'green',\n",
       " 'blue',\n",
       " 'indigo',\n",
       " 'violet',\n",
       " 'black',\n",
       " 'white',\n",
       " 'gray']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase. Do NOT reply iwth anything else.\",\n",
    "     ),\n",
    "    (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items=\"10\",\n",
    "    question=\"What are the colors?\"\n",
    "    )\n",
    "\n",
    "#chat.predict_messages(prompt)\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(result.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make above cell very simple and short by creating \"chain\".\n",
    "- Need Template, Output Parser, and Chat Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pikachu', 'charizard', 'bulbasaur', 'squirtle', 'jigglypuff']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase. Do NOT reply iwth anything else.\",\n",
    "     ),\n",
    "    (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# this chain combines template, language model and Output Parser\n",
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "# this is example. you can also chain among chains\n",
    "# chain_one = template | chat | CommaOutoputParser()\n",
    "# chain_two = template2 | chat | OutputParser()\n",
    "# first, combine chain_one, and you can use output of chain_one to use it with chain_two\n",
    "# all = chain_one | chain_two| output\n",
    "\n",
    "chain.invoke({\n",
    "    \"max_items\":5,\n",
    "    \"question\":\"What are Pokemons?\"\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining Chains\n",
    "\n",
    "- Prompt: Dictionary\n",
    "- Retriever: Single string\n",
    "- LLM: Single string, list of chat messages or a PromptValue\n",
    "- OutputParser: The output of an LLM or ChatModel\n",
    "- ChatModel: Single string, list of chat messages or a PromptValue\n",
    "- Tool: Single string or dictionary, depending on the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy example\n",
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", '''You are a world-class international chef.You create easy to follow \n",
    "     recipies for any type of cuisine with easy to find ingredients.'''),\n",
    "    (\"human\", \"I want to cook {cuisine} food\"),   \n",
    "])\n",
    "\n",
    "# create chef chain then send chat to LLM\n",
    "# we are going to receive recipe from a chef, and we will adapt it to use vegetarian ingredients.\n",
    "chef_chain = chef_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", '''You are a vegetarian chef specialized on making traditional recipies\n",
    "     vegetarian. You find alterative ingredients and explain their preparation. You\n",
    "     don't radically modify the recipe. If there is no alternative for a food just \n",
    "     say you don't know how to replace it.'''),\n",
    "    (\"human\", \"{recipe}\")\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = chef_chain | veg_chain\n",
    "final_chain.invoke({\n",
    "    \"cuisine\": \"indian\"  \n",
    "})\n",
    "\n",
    "veg_chain.invoke({\n",
    "    \"recipe\": \"chatmodel\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
